{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel environment where the agent is located"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, the environment and environment in which the agent is located are mainly defined as the reward of the action selected by the agent. In class Env, the following variables and functions are defined:\n",
    "variable:\n",
    "* _actions_: indicates the optional actions of the agent, using the list to represent\n",
    "* _n_actions_: record the number of optional actions, used in the neural network output in subsequent DQN\n",
    "* _n_features_: The number of attributes for recording observations, 4 in this project\n",
    "* _time_env_state_: use a dictionary to record a specific moment, the state of the environment\n",
    "function:\n",
    "* \\_\\__init_\\_\\_(_self_): initialize the function, define the variable\n",
    "* _update_\\__State_(_self_): get the current environment information from the environment data, and return\n",
    "* _reset_(_self_): reset the environment, (this can be removed)\n",
    "* _step_(_self_, _action_): according to the action selected by the agent, return the status value and reward of the next moment of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_Generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a7d6b0f0e58b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdata_Generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_Generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'data_Generator'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from data_Generator import data_Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    def __init__(self, **kwargs):\n",
    "        # super(Env, self).__init__(**kwargs)\n",
    "        self.actions = [\n",
    "            \"Channel_1\",\n",
    "            \"Channel_6\",\n",
    "            \"Channel_11\"\n",
    "        ]\n",
    "\n",
    "        self.tx_power_list = [20, 24, 27, 30]\n",
    "        self.n_actions = len(self.actions)\n",
    "        self.n_features = 12\n",
    "        self.state =\"\"\n",
    "        self.time = 1\n",
    "        self.count = 0\n",
    "        self.countc = 0\n",
    "        self.count_history = []\n",
    "        self.correct_rate = []\n",
    "        self.time_env_state = {}\n",
    "        self.list = data_Generator()\n",

    "        self.num = 0 # set file read counter to 0 = first line\n",
    "        self.log = kwargs.get('log', print) # logging function\n",
    "        self.statusPeriod = kwargs.get('statusPeriod', 1) # period at which to report status\n",

    "\n",
    "    def data(self):\n",
    "\n",
    "        channel = self.list[self.num]\n",
    "        self.num +=1\n",
    "        return channel\n",
    "\n",
    "    \n",
    "    def update_State(self):\n",
    "        self.time += 1\n",
    "        filename = 'data.csv'\n",
    "\n",
    "\n",
    "        self.time_env_state[\"current\"] = {\"Channel_1\": self.data(),\n",
    "                                              \"Channel_6\": self.data(),\n",
    "                                              \"Channel_11\":self.data(),}\n",
    "\n",
    "        return self.time_env_state[\"current\"]\n",
    "\n",
    "    def reset(self):\n",
    "        self.update_State()\n",
    "        #self.state = \"Channel_1\"\n",
    "        return self.time_env_state[\"current\"]\n",
    "\n",
    "    def value(self, state):\n",
    "        # state[:2] = [state[0], state[1]] = [RSSI_1, RSSI_2]\n",
    "        # state[2] = tx_power\n",
    "        # state[3] = spectral_density\n",
    "        RSSI_1 = state[0]\n",
    "        RSSI_2 = state[1]\n",
    "        tx_power = state[2]\n",
    "        spectral_density = state[3]\n",
    "        \n",
    "        # Value returned is -power_sum([RSSI_1, RSSI_2]) + tx_power + (100 - spectral_density)\n",
    "        # Higher, more positive is better, hence abs() for power sum of RSSIs.\n",
    "        return np.abs(10*np.log10(np.sum(10**(np.array([RSSI_1, RSSI_2])/10)))) + tx_power + (100 - spectral_density)\n",
    "        # pass\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        value = 0\n",
    "        max_value = -np.Inf # min. possible value\n",
    "        action_key = \"\"\n",
    "        # \"\"\"\n",
    "        # Find value function output for each chan. in current state.\n",
    "        for key in self.time_env_state[\"current\"]:\n",
    "\n",
    "            value = self.value(self.time_env_state[\"current\"][key])\n",
    "            \n",
    "            # 比较 - compare & update current max. value, return action for max. value\n",
    "            if value > max_value:\n",
    "                max_value = value\n",
    "                action_key = key\n",
    "        #print('{}:time_env_value{}\\n'.format(self.time,self.time_env_state))\n",
    "        # \"\"\"\n",
    "        self.log('{}: action {} has max. value {}\\n'.format(self.time, action_key, max_value), period=self.statusPeriod, counter=self.time)\n",
    "        \n",
    "        # print(self.time)\n",
    "        next_state = action\n",
    "\n",
    "        if next_state == action_key:\n",
    "            self.count +=1\n",
    "            self.countc +=1\n",

    "            reward = 5 # 1 # self.count\n",
    "            self.log('{}: selected action = {} with max. value, reward = {}\\n'.format(self.time, action, reward), period=self.statusPeriod, counter=self.time)\n",

    "            \n",
    "        else:\n",
    "            reward = 0\n",
    "            self.count = 0\n",
    "\n",
    "            \n",
    "        self.count_history.append(self.count)\n",
    "        self.correct_rate.append(self.count/(len(self.count_history)))\n",
    "            \n",
    "        self.state = next_state\n",
    "        self.update_State()\n",
    "        return self.time_env_state[\"current\"], self.time_env_state[\"current\"][next_state], reward\n",
    "    \n",
    "    def plot_count(self):\n",
    "        plt.figure(1)\n",
    "        plt.plot(self.count_history, '.-')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xlabel('training steps')\n",
    "        plt.show()\n",
    "        plt.figure(2)\n",
    "        plt.plot(self.correct_rate, '.-')\n",
    "        plt.ylabel('Correct_rate')\n",
    "        plt.xlabel('training steps')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
